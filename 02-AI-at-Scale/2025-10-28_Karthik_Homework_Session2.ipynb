{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b2d9ec-6cfd-4810-8e3f-f5759dacb044",
   "metadata": {},
   "source": [
    "1. What model sizes work with different TP degrees?\n",
    "\n",
    "- From my runs, TP has a clear impact on memory capacity. With TP=1, the model only fits up to 12 layers, since 16 layers triggers an out-of-memory error. Increasing to TP=2 lets 16 layers fit successfully, but 32 layers still fail. TP=4 is the only configuration that can run the full 32-layer model in this setup, completing in 212.86 seconds. So higher tensor parallelism enables deeper models by distributing memory across GPUs, allowing configurations that would otherwise exceed single-GPU limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a4cc3-7307-44ae-9c15-55b6b90e5114",
   "metadata": {},
   "source": [
    "2. How does performance change for an 8-layer model with TP of 1, 2, and 4?\n",
    "- For the smaller 8-layer model, the performance difference across TP settings is modest. TP=1 and TP=2 essentially perform the same, at about 121 seconds per run. Moving to TP=4 improves speed, reducing runtime to 110.23 seconds, roughly a 9 percent improvement compared to TP=1. This suggests that at small model sizes, TP adds communication overhead that offsets most of the gains, but a higher TP degree can still give some speedup once the model is large enough to use the extra parallelism effectively.\n",
    "![HW2](hw2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512481be-5b5c-4123-96d5-42acce5ac486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
